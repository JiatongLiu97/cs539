{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "202ed614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# visualize feature maps output from each block in the vgg model\n",
    "# https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import Model\n",
    "from matplotlib import pyplot\n",
    "from numpy import expand_dims\n",
    "\n",
    "\n",
    "# load the model\n",
    "model = VGG16()\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "163a7743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 block1_conv1 (None, 224, 224, 64)\n",
      "2 block1_conv2 (None, 224, 224, 64)\n",
      "4 block2_conv1 (None, 112, 112, 128)\n",
      "5 block2_conv2 (None, 112, 112, 128)\n",
      "7 block3_conv1 (None, 56, 56, 256)\n",
      "8 block3_conv2 (None, 56, 56, 256)\n",
      "9 block3_conv3 (None, 56, 56, 256)\n",
      "11 block4_conv1 (None, 28, 28, 512)\n",
      "12 block4_conv2 (None, 28, 28, 512)\n",
      "13 block4_conv3 (None, 28, 28, 512)\n",
      "15 block5_conv1 (None, 14, 14, 512)\n",
      "16 block5_conv2 (None, 14, 14, 512)\n",
      "17 block5_conv3 (None, 14, 14, 512)\n"
     ]
    }
   ],
   "source": [
    "# summarize feature map shapes\n",
    "for i in range(len(model.layers)):\n",
    "    layer = model.layers[i]\n",
    "    # check for convolutional layer\n",
    "    if 'conv' not in layer.name:\n",
    "        continue\n",
    "    # summarize output shape\n",
    "    print(i, layer.name, layer.output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a2ac8",
   "metadata": {},
   "source": [
    "We can use this information and design a new model that is a subset of the layers in the full VGG16 model. The model would have the same input layer as the original model, but the output would be the output of a given convolutional layer, which we know would be the activation of the layer or the feature map. For example, after loading the VGG model, we can define a new model that outputs a feature map from the first convolutional layer (index 1) as follows. Making a prediction with this model will give the feature map for the first convolutional layer for a given provided input image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cb9aaea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'input_1:0' shape=(None, 224, 224, 3) dtype=float32>]\n",
      "block1_conv1\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "=================================================================\n",
      "Total params: 1,792\n",
      "Trainable params: 1,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# redefine model to output right after the first hidden layer\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[1].output)\n",
    "print(model.layers[1].name)\n",
    "# this model is much smaller than the VGG16 model, but still uses \n",
    "# the same weights (filters) in the first convolutional layer as \n",
    "# the VGG16 model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae9f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image with the required shape\n",
    "img = load_img('bird.jpg', target_size=(224, 224))\n",
    "# convert the image to an array\n",
    "# the image PIL object needs to be converted to a NumPy array of \n",
    "# pixel data and expanded from a 3D array to a 4D array with the \n",
    "# dimensions of [samples, rows, cols, channels], where we only \n",
    "# have one sample.\n",
    "img = img_to_array(img)\n",
    "# expand dimensions so that it represents a single 'sample'\n",
    "img = expand_dims(img, axis=0)\n",
    "# prepare the image (e.g. scale pixel values for the vgg)\n",
    "# See https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/preprocess_input\n",
    "img = preprocess_input(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c8352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature map for first hidden layer\n",
    "feature_maps = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37800da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result will be a feature map with 224x224x64. \n",
    "# We can plot all 64 two-dimensional images as an 8Ã—8 square of images.\n",
    "# plot the output from each block\n",
    "# plot all 64 maps in an 8x8 squares\n",
    "square = 8\n",
    "ix = 1\n",
    "for _ in range(square):\n",
    "\tfor _ in range(square):\n",
    "\t\t# specify subplot and turn of axis\n",
    "\t\tax = pyplot.subplot(square, square, ix)\n",
    "\t\tax.set_xticks([])\n",
    "\t\tax.set_yticks([])\n",
    "\t\t# plot filter channel in grayscale\n",
    "\t\tpyplot.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n",
    "\t\tix += 1\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9517849f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
